{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.4 64-bit ('base': conda)",
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f958bdd04a238e53230fa8372db10ddee88fbe838d3660515cd74e50e6d77f98"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import sklearn as sk\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "tf.compat.v1.set_random_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los csv\n",
    "df_local = pd.read_csv(\"./unified-lightcurves-local.csv\").iloc[:, 1:]\n",
    "df_global = pd.read_csv(\"./unified-lightcurves-global.csv\").iloc[:, 1:]\n",
    "df_stellar = pd.read_csv(\"./unified-stellar-params.csv\").iloc[:, 1:]\n",
    "\n",
    "display(df_local)\n",
    "display(df_global)\n",
    "display(df_stellar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fluxes = df_local.iloc[:,4:]\n",
    "local_labels = df_local.iloc[:,3]\n",
    "\n",
    "global_fluxes = df_global.iloc[:,4:]\n",
    "global_labels = df_global.iloc[:,3]\n",
    "\n",
    "stellar_infos = df_stellar.iloc[:,2:]\n",
    "stellar_labels = df_stellar.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto es porque no estas normalizado los datos estelares\n",
    "x = stellar_infos.values\n",
    "x_scaled = sk.preprocessing.MinMaxScaler().fit_transform(x)\n",
    "stellar_infos = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "source": [
    "## Particionado de datos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_train, xl_test, yl_train, yl_test = sk.model_selection.train_test_split(\n",
    "    local_fluxes, local_labels, test_size=0.3, random_state=11)\n",
    "    \n",
    "xg_train, xg_test, yg_train, yg_test = sk.model_selection.train_test_split(\n",
    "    global_fluxes, global_labels, test_size=0.3, random_state=11)\n",
    "    \n",
    "xs_train, xs_test, ys_train, ys_test = sk.model_selection.train_test_split(\n",
    "    stellar_infos, stellar_labels, test_size=0.3, random_state=11)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xl_train.shape, xl_test.shape, yl_train.shape, yl_test.shape)\n",
    "print(xg_train.shape, xg_test.shape, yg_train.shape, yg_test.shape)\n",
    "print(xs_train.shape, xs_test.shape, ys_train.shape, ys_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos las dimensiones\n",
    "n_outputs = 1\n",
    "nL_timesteps, nL_features  = xl_train.shape[0], xl_train.shape[1]\n",
    "nG_timesteps, nG_features  = xg_train.shape[0], xg_train.shape[1]\n",
    "nS_timesteps, nS_features  = xs_train.shape[0], xs_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nL_timesteps, nL_features)\n",
    "print(nG_timesteps, nG_features)\n",
    "print(nS_timesteps, nS_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expandimos las dimensiones de train \n",
    "xle_train = np.expand_dims(xl_train,axis=-1) \n",
    "yle_train = np.array(yl_train)\n",
    "\n",
    "xge_train = np.expand_dims(xg_train,axis=-1)\n",
    "yge_train = np.array(yg_train)\n",
    "\n",
    "xse_train = np.expand_dims(xs_train,axis=-1)\n",
    "yse_train = np.array(ys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xl_train.shape, yl_train.shape)\n",
    "print(xle_train.shape, yle_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expandimos las dimensiones de test\n",
    "xle_test = np.expand_dims(xl_test,axis=-1)\n",
    "yle_test = np.array(yl_test)\n",
    "\n",
    "xge_test = np.expand_dims(xg_test,axis=-1)\n",
    "yge_test = np.array(yg_test)\n",
    "\n",
    "xse_test = np.expand_dims(xs_test,axis=-1)\n",
    "yse_test = np.array(ys_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xl_test.shape, yl_test.shape)\n",
    "print(xle_test.shape, yle_test.shape)"
   ]
  },
  {
   "source": [
    "## Construcción Red Neuronal"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Red para vistas locales"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first input model\n",
    "inputLocalView = tf.keras.layers.Input(shape=(nL_features, 1))\n",
    "inputLocalView.set_shape([nL_timesteps, nL_features, 1]) # 4266 x 101\n",
    "\n",
    "CL1 = tf.keras.layers.Conv1D(filters=16, kernel_size=5, activation='relu')(inputLocalView)\n",
    "CL2 = tf.keras.layers.Conv1D(filters=16, kernel_size=5, activation='relu')(CL1)\n",
    "\n",
    "ML1 = tf.keras.layers.MaxPooling1D(pool_size=7, strides=2)(CL2)\n",
    "\n",
    "CL3 = tf.keras.layers.Conv1D(filters=32, kernel_size=5, activation='relu')(ML1)\n",
    "CL4 = tf.keras.layers.Conv1D(filters=32, kernel_size=5, activation='relu')(CL3)\n",
    "\n",
    "ML2 = tf.keras.layers.MaxPooling1D(pool_size=7, strides=2)(CL4)\n",
    "flat1 = tf.keras.layers.Flatten()(ML2)"
   ]
  },
  {
   "source": [
    "### Red para vistas globales"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputGlobalView = tf.keras.layers.Input(shape=(nG_features, 1))\n",
    "inputGlobalView.set_shape([nG_timesteps, nG_features, 1])  # 4266 x 1001\n",
    "\n",
    "\n",
    "CG1 = tf.keras.layers.Conv1D(filters=16, kernel_size=5, activation='relu')(inputGlobalView)\n",
    "CG2 = tf.keras.layers.Conv1D(filters=16, kernel_size=5, activation='relu')(CG1)\n",
    "\n",
    "MG1 = tf.keras.layers.MaxPooling1D(pool_size=3, strides=2)(CG2)\n",
    "\n",
    "CG3 = tf.keras.layers.Conv1D(filters=32, kernel_size=5, activation='relu')(MG1)\n",
    "CG4 = tf.keras.layers.Conv1D(filters=32, kernel_size=5, activation='relu')(CG3)\n",
    "\n",
    "MG2 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=2)(CG4)\n",
    "\n",
    "CG5 = tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu')(MG2)\n",
    "CG6 = tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu')(CG5)\n",
    "\n",
    "MG3 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=2)(CG6)\n",
    "\n",
    "CG7 = tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu')(MG3)\n",
    "CG8 = tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu')(CG7)\n",
    "\n",
    "MG4 = tf.keras.layers.MaxPooling1D(pool_size=2, strides=2)(CG8)\n",
    "\n",
    "flat2 = tf.keras.layers.Flatten()(MG4)\n"
   ]
  },
  {
   "source": [
    "### Red para parámetros estelares"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StellarParam6PInput = tf.keras.layers.Input(shape=(nS_features, 1))\n",
    "StellarParam6PInput.set_shape([nS_timesteps, nS_features, 1])  # 4266 x 15\n",
    "\n",
    "#StellarParam6PInput=(nS_features,1)\n",
    "flat3 = tf.keras.layers.Flatten()(StellarParam6PInput)\n"
   ]
  },
  {
   "source": [
    "### Unificación de redes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_48\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_44 (InputLayer)           [(4266, 1001, 1)]    0                                            \n__________________________________________________________________________________________________\nconv1d_158 (Conv1D)             (4266, 997, 16)      96          input_44[0][0]                   \n__________________________________________________________________________________________________\nconv1d_159 (Conv1D)             (4266, 993, 16)      1296        conv1d_158[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling1d_78 (MaxPooling1D) (4266, 496, 16)      0           conv1d_159[0][0]                 \n__________________________________________________________________________________________________\nconv1d_160 (Conv1D)             (4266, 492, 32)      2592        max_pooling1d_78[0][0]           \n__________________________________________________________________________________________________\nconv1d_161 (Conv1D)             (4266, 488, 32)      5152        conv1d_160[0][0]                 \n__________________________________________________________________________________________________\ninput_43 (InputLayer)           [(4266, 101, 1)]     0                                            \n__________________________________________________________________________________________________\nmax_pooling1d_79 (MaxPooling1D) (4266, 244, 32)      0           conv1d_161[0][0]                 \n__________________________________________________________________________________________________\nconv1d_154 (Conv1D)             (4266, 97, 16)       96          input_43[0][0]                   \n__________________________________________________________________________________________________\nconv1d_162 (Conv1D)             (4266, 240, 64)      10304       max_pooling1d_79[0][0]           \n__________________________________________________________________________________________________\nconv1d_155 (Conv1D)             (4266, 93, 16)       1296        conv1d_154[0][0]                 \n__________________________________________________________________________________________________\nconv1d_163 (Conv1D)             (4266, 236, 64)      20544       conv1d_162[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling1d_76 (MaxPooling1D) (4266, 44, 16)       0           conv1d_155[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling1d_80 (MaxPooling1D) (4266, 118, 64)      0           conv1d_163[0][0]                 \n__________________________________________________________________________________________________\nconv1d_156 (Conv1D)             (4266, 40, 32)       2592        max_pooling1d_76[0][0]           \n__________________________________________________________________________________________________\nconv1d_164 (Conv1D)             (4266, 116, 128)     24704       max_pooling1d_80[0][0]           \n__________________________________________________________________________________________________\nconv1d_157 (Conv1D)             (4266, 36, 32)       5152        conv1d_156[0][0]                 \n__________________________________________________________________________________________________\nconv1d_165 (Conv1D)             (4266, 114, 128)     49280       conv1d_164[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling1d_77 (MaxPooling1D) (4266, 15, 32)       0           conv1d_157[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling1d_81 (MaxPooling1D) (4266, 57, 128)      0           conv1d_165[0][0]                 \n__________________________________________________________________________________________________\ninput_45 (InputLayer)           [(4266, 15, 1)]      0                                            \n__________________________________________________________________________________________________\nflatten_38 (Flatten)            (4266, 480)          0           max_pooling1d_77[0][0]           \n__________________________________________________________________________________________________\nflatten_39 (Flatten)            (4266, 7296)         0           max_pooling1d_81[0][0]           \n__________________________________________________________________________________________________\nflatten_40 (Flatten)            (4266, 15)           0           input_45[0][0]                   \n__________________________________________________________________________________________________\nconcatenate_11 (Concatenate)    (4266, 7791)         0           flatten_38[0][0]                 \n                                                                 flatten_39[0][0]                 \n                                                                 flatten_40[0][0]                 \n__________________________________________________________________________________________________\ndense_135 (Dense)               (4266, 256)          1994752     concatenate_11[0][0]             \n__________________________________________________________________________________________________\ndense_136 (Dense)               (4266, 256)          65792       dense_135[0][0]                  \n__________________________________________________________________________________________________\ndense_137 (Dense)               (4266, 256)          65792       dense_136[0][0]                  \n__________________________________________________________________________________________________\ndense_138 (Dense)               (4266, 256)          65792       dense_137[0][0]                  \n__________________________________________________________________________________________________\ndense_139 (Dense)               (4266, 1)            257         dense_138[0][0]                  \n==================================================================================================\nTotal params: 2,315,489\nTrainable params: 2,315,489\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "# merge input models\n",
    "merge = tf.keras.layers.concatenate([flat1, flat2, flat3])\n",
    "\n",
    "# interpretation model\n",
    "hidden1 = tf.keras.layers.Dense(256, activation='relu')(merge)\n",
    "hidden2 = tf.keras.layers.Dense(256, activation='relu')(hidden1)\n",
    "hidden3 = tf.keras.layers.Dense(256, activation='relu')(hidden2)\n",
    "hidden4 = tf.keras.layers.Dense(256, activation='relu')(hidden3)\n",
    "\n",
    "output = tf.keras.layers.Dense(n_outputs, activation='tanh')(hidden4)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputLocalView,inputGlobalView,StellarParam6PInput], outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (4266, 101, 1) for input Tensor(\"input_43:0\", shape=(4266, 101, 1), dtype=float32), but it was called on an input with incompatible shape (474, 101, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (4266, 1001, 1) for input Tensor(\"input_44:0\", shape=(4266, 1001, 1), dtype=float32), but it was called on an input with incompatible shape (474, 1001, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (4266, 15, 1) for input Tensor(\"input_45:0\", shape=(4266, 15, 1), dtype=float32), but it was called on an input with incompatible shape (474, 15, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (4266, 101, 1) for input Tensor(\"input_43:0\", shape=(4266, 101, 1), dtype=float32), but it was called on an input with incompatible shape (474, 101, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (4266, 1001, 1) for input Tensor(\"input_44:0\", shape=(4266, 1001, 1), dtype=float32), but it was called on an input with incompatible shape (474, 1001, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (4266, 15, 1) for input Tensor(\"input_45:0\", shape=(4266, 15, 1), dtype=float32), but it was called on an input with incompatible shape (474, 15, 1).\n",
      "9/9 [==============================] - 11s 1s/step - loss: nan - accuracy: 0.7583\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 10s 1s/step - loss: nan - accuracy: 0.7583\n",
      "Epoch 3/50\n",
      "3/9 [=========>....................] - ETA: 4s - loss: nan - accuracy: 0.7539"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-281-d69c0bc37a79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# divisores 4266: 1, 2, 3, 6, 9, 18, 27, 54, 79, 158, 237, 474, 711, 1422, 2133, 4266\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m474\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mAjuste\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxle_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxge_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxse_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myle_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# divisores 4266: 1, 2, 3, 6, 9, 18, 27, 54, 79, 158, 237, 474, 711, 1422, 2133, 4266\n",
    "bs = 474\n",
    "Ajuste = model.fit([xle_train, xge_train, xse_train], yle_train, epochs=50, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([1.9541033e-01, 8.8378060e-01, 2.0661591e-01, ..., 7.9641171e-02,\n       2.3715198e-04, 1.4054148e-01], dtype=float32)"
     },
     "metadata": {}
    }
   ],
   "source": [
    "y_pred_keras = model.predict([xle_test,xge_test, xse_test]).ravel()\n",
    "display(y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Threshold=0.196187, G-Mean=0.695\n"
     ]
    }
   ],
   "source": [
    "# Defino las métricas\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(yle_test, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "gmeans = np.sqrt(tpr_keras * (1-fpr_keras))\n",
    "\n",
    "# localiza el índice del mayor g-mean\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds_keras[ix], gmeans[ix]))\n"
   ]
  },
  {
   "source": [
    "# \"#############\"\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umbral estándar\n",
    "labels_Standart = (y_pred_keras >= 0.5).astype(np.int)\n",
    "PhiM_Standart = matthews_corrcoef(yle_test, labels_Standart)\n",
    "Matrix_Standart = confusion_matrix(yle_test, labels_Standart)\n",
    "\n",
    "#Imprimo por pantalla las métricas\n",
    "auc_keras, PhiM_Standart, print(Matrix_Standart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umbral OPT\n",
    "labels_OPT =(y_pred_keras >= thresholds_keras[ix]).astype(np.int)\n",
    "PhiCoeff_OPT = matthews_corrcoef(yle_test, labels_OPT)\n",
    "Matrix_OPT = confusion_matrix(yle_test, labels_OPT)\n",
    "F_Measure_OPT = f1_score(yle_test, labels_OPT, average='binary')\n",
    "Accuracy_OPT= accuracy_score(yle_test, labels_OPT, normalize=True)\n",
    "Recall_OPT= recall_score(yle_test, labels_OPT, average=None)\n",
    "Average_precision_OPT= average_precision_score(yle_test, labels_OPT)\n",
    "\n",
    "\n",
    "#Imprimo por pantalla las métricas\n",
    "print(\"AUC:\", auc_keras)\n",
    "print(\"F_Measure:\", F_Measure_OPT)\n",
    "print(\"PhiCoeff:\", PhiCoeff_OPT)\n",
    "print(\"Average_precision:\", Average_precision_OPT)\n",
    "print(\"Accuracy:\", Accuracy_OPT)\n",
    "print(\"Recall:\", Recall_OPT)\n",
    "print(\"Matriz de confusión:\")\n",
    "print( Matrix_OPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploteo la matrix de confusión\n",
    "import seaborn as sn\n",
    "df_cm = pd.DataFrame(Matrix_OPT, index = [i for i in \"01\"],\n",
    "                  columns = [i for i in \"01\"])\n",
    "\n",
    "plt.figure(0.5)\n",
    "heat_map = sn.heatmap(df_cm, xticklabels=True, yticklabels=True, annot=True, annot_kws = {\"ha\": 'center',\"va\": 'bottom'},cbar=False)\n",
    "#heat_map.set_yticklabels(heat_map.get_yticklabels(), rotation=0)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "for text in heat_map.texts:\n",
    "    text.set_size(14)\n",
    "    text.set_weight('bold')\n",
    "    if text.get_text() == '5':\n",
    "        text.set_color('black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='CNN (area = {:.3f})'.format(auc_keras))\n",
    "plt.scatter(fpr_keras[ix], tpr_keras[ix], marker='o', color='black', label='Best')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras_tot = np.array([])\n",
    "y_pred_rf_tot = np.array([])\n",
    "y_test_total = np.array([])\n",
    "\n",
    "xl_train, xl_test, yl_train, yl_test = train_test_split(LocalView.iloc[:,2:], LocalView.iloc[:,1], test_size=0.3, random_state=11)\n",
    "xg_train, xg_test, yg_train, yg_test = train_test_split(GlobalView.iloc[:,2:], GlobalView.iloc[:,1], test_size=0.3, random_state=11)\n",
    "xs_train, xs_test, ys_train, ys_test = train_test_split(StellarParam6P.iloc[:,2:], StellarParam6P.iloc[:,1], test_size=0.3, random_state=11)\n",
    "    \n",
    "   \n",
    "    #Definimos las dimensiones\n",
    "n_outputs = 1\n",
    "nL_timesteps, nL_features  = xl_train.shape[0], xl_train.shape[1]\n",
    "nG_timesteps, nG_features  = xg_train.shape[0], xg_train.shape[1]\n",
    "nS_timesteps, nS_features  = xs_train.shape[0], xs_train.shape[1]\n",
    "      \n",
    "    #Expandimos las dimensiones\n",
    "xle_train = np.expand_dims(xl_train,axis=-1) # axis=-3 para que se adapte a la forma del tensor\n",
    "yle_train = np.array(yl_train) # Hay que trasponer \n",
    "xge_train = np.expand_dims(xg_train,axis=-1)\n",
    "yge_train = np.array(yg_train)\n",
    "xse_train = np.expand_dims(xs_train,axis=-1)\n",
    "yse_train = np.array(ys_train)\n",
    "    \n",
    "    \n",
    "    # Multiple Inputs\n",
    "\n",
    "    # first input model\n",
    "inputLocalView = Input(shape=(nL_features, 1))\n",
    "inputLocalView.set_shape([nL_timesteps, nL_features, 1])\n",
    "\n",
    "CL1 = Conv1D(filters=16, kernel_size=5, activation='relu')(inputLocalView)\n",
    "CL2 = Conv1D(filters=16, kernel_size=5, activation='relu')(CL1)\n",
    "\n",
    "ML1 = MaxPooling1D(pool_size=7, strides=2)(CL2)\n",
    "\n",
    "CL3 = Conv1D(filters=32, kernel_size=5, activation='relu')(ML1)\n",
    "CL4 = Conv1D(filters=32, kernel_size=5, activation='relu')(CL3)\n",
    "\n",
    "ML2 = MaxPooling1D(pool_size=7, strides=2)(CL4)\n",
    "flat1 = Flatten()(ML2)\n",
    "\n",
    "    # second input model\n",
    "\n",
    "inputGlobalView = Input(shape=(nG_features, 1))\n",
    "inputGlobalView.set_shape([nG_timesteps, nG_features, 1])\n",
    "\n",
    "CG1 = Conv1D(filters=16, kernel_size=5, activation='relu')(inputGlobalView)\n",
    "CG2 = Conv1D(filters=16, kernel_size=5, activation='relu')(CG1)\n",
    "\n",
    "MG1 = MaxPooling1D(pool_size=3, strides=2)(CG2)\n",
    "\n",
    "CG3 = Conv1D(filters=32, kernel_size=5, activation='relu')(MG1)\n",
    "CG4 = Conv1D(filters=32, kernel_size=5, activation='relu')(CG3)\n",
    "\n",
    "MG2 = MaxPooling1D(pool_size=2, strides=2)(CG4)\n",
    "\n",
    "CG5 = Conv1D(filters=64, kernel_size=5, activation='relu')(MG2)\n",
    "CG6 = Conv1D(filters=64, kernel_size=5, activation='relu')(CG5)\n",
    "\n",
    "MG3 = MaxPooling1D(pool_size=2, strides=2)(CG6)\n",
    "\n",
    "CG7 = Conv1D(filters=128, kernel_size=3, activation='relu')(MG3)\n",
    "CG8 = Conv1D(filters=128, kernel_size=3, activation='relu')(CG7)\n",
    "\n",
    "MG4 = MaxPooling1D(pool_size=2, strides=2)(CG8)\n",
    "\n",
    "flat2 = Flatten()(MG4)\n",
    "\n",
    "    # third input model\n",
    "\n",
    "StellarParam6PInput = Input(shape=(nS_features, 1))\n",
    "StellarParam6PInput.set_shape([nS_timesteps, nS_features, 1])\n",
    "\n",
    "    #StellarParam6PInput=(nS_features,1)\n",
    "flat3 = Flatten()(StellarParam6PInput)\n",
    "    # merge input models\n",
    "merge = concatenate([flat1, flat2, flat3])\n",
    "\n",
    "    # interpretation model\n",
    "hidden1 = Dense(256, activation='relu')(merge)\n",
    "hidden2 = Dense(256, activation='relu')(hidden1)\n",
    "hidden3 = Dense(256, activation='relu')(hidden2)\n",
    "hidden4 = Dense(256, activation='relu')(hidden3)\n",
    " #2output = Dense(n_outputs, activation='tanh')(hidden4)\n",
    "output = Dense(n_outputs, activation='tanh')(hidden4)\n",
    "model = Model(inputs=[inputLocalView, inputGlobalView,StellarParam6PInput], outputs=output)\n",
    "    #loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'ce']\n",
    "model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "    #loss_weights=['main_output': 1., 'aux_output': 0.2]) por si queremos darles pesos diferentes\n",
    "\n",
    "batch_size=119\n",
    "\n",
    "#Aumento número de muestras\n",
    "for i in range(10):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    # Divido entre entrenamiento y test\n",
    "    xl_train, xl_test, yl_train, yl_test = train_test_split(LocalView.iloc[:,2:], LocalView.iloc[:,1], test_size=0.3, random_state=11+i)\n",
    "    xg_train, xg_test, yg_train, yg_test = train_test_split(GlobalView.iloc[:,2:], GlobalView.iloc[:,1], test_size=0.3, random_state=11+i)\n",
    "    xs_train, xs_test, ys_train, ys_test = train_test_split(StellarParam6P.iloc[:,2:], StellarParam6P.iloc[:,1], test_size=0.3, random_state=11+i)\n",
    "    \n",
    "  \n",
    "    # fit forma 2\n",
    "    FIT = model.fit([xle_train, xge_train, xse_train], yle_train,\n",
    "          epochs=50, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    xle_test = np.expand_dims(xl_test,axis=-1)\n",
    "    yle_test = np.array(yl_test) \n",
    "    xge_test = np.expand_dims(xg_test,axis=-1)\n",
    "    yge_test = np.array(yg_test)\n",
    "    xse_test = np.expand_dims(xs_test,axis=-1)\n",
    "    yse_test = np.array(ys_test)\n",
    "    \n",
    "    \n",
    "    # Creo la RoC\n",
    "    y_pred_kerasC = model.predict([xle_test,xge_test,xse_test]).ravel()\n",
    "    \n",
    "    \n",
    "    #Lleno los vectores totales\n",
    "    y_pred_keras_tot = np.concatenate((y_pred_keras_tot,y_pred_kerasC))\n",
    "    \n",
    "    y_test_total = np.concatenate((y_test_total,yle_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino las métricas\n",
    "\n",
    "fpr_kerasTotal, tpr_kerasTotal, thresholds_kerasTotal = roc_curve(y_test_total, y_pred_keras_tot)\n",
    "auc_kerasTotal = auc(fpr_kerasTotal, tpr_kerasTotal)\n",
    "gmeans = np.sqrt(tpr_kerasTotal * (1-fpr_kerasTotal))\n",
    "# localiza el índice del mayor g-mean\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds_kerasTotal[ix], gmeans[ix]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umbral estándar\n",
    "labels_Standart = (y_pred_keras_tot >= 0.5).astype(np.int)\n",
    "PhiCoeff_Standart = matthews_corrcoef(y_test_total, labels_Standart)\n",
    "Matrix_Standart = confusion_matrix(y_test_total, labels_Standart)\n",
    "F_Measure_Standart = f1_score(y_test_total, labels_Standart, average='binary')\n",
    "\n",
    "#Imprimo por pantalla las métricas\n",
    "auc_kerasTotal, PhiM_Standart,F_Measure_Standart, print(Matrix_Standart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umbral OPT\n",
    "labels_OPT =(y_pred_keras_tot >= thresholds_kerasTotal[ix]).astype(np.int)\n",
    "PhiCoeff_OPT = matthews_corrcoef(y_test_total, labels_OPT)\n",
    "Matrix_OPT = confusion_matrix(y_test_total, labels_OPT)\n",
    "F_Measure_OPT = f1_score(y_test_total, labels_OPT, average='binary')\n",
    "Accuracy_OPT= accuracy_score(y_test_total, labels_OPT, normalize=True)\n",
    "Recall_OPT= recall_score(y_test_total, labels_OPT, average=None)\n",
    "Average_precision_OPT= average_precision_score(y_test_total, labels_OPT)\n",
    "\n",
    "\n",
    "#Imprimo por pantalla las métricas\n",
    "print(\"AUC:\", auc_kerasTotal)\n",
    "print(\"F_Measure:\", F_Measure_OPT)\n",
    "print(\"PhiCoeff:\", PhiCoeff_OPT)\n",
    "print(\"Average_precision:\", Average_precision_OPT)\n",
    "print(\"Accuracy:\", Accuracy_OPT)\n",
    "print(\"Recall:\", Recall_OPT)\n",
    "print(\"Matriz de confusión:\")\n",
    "print( Matrix_OPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploteo la matrix de confusión\n",
    "\n",
    "df_cm_OPT = pd.DataFrame(Matrix_OPT, index = [i for i in \"01\"],\n",
    "                  columns = [i for i in \"01\"])\n",
    "plt.figure(0.5)\n",
    "heat_map = sn.heatmap(df_cm_OPT, xticklabels=True, yticklabels=True, annot=True, fmt='g', annot_kws = {\"ha\": 'center',\"va\": 'bottom'},cbar=False)\n",
    "#heat_map.set_yticklabels(heat_map.get_yticklabels(), rotation=0)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "for text in heat_map.texts:\n",
    "    text.set_size(14)\n",
    "    text.set_weight('bold')\n",
    "    if text.get_text() == '33':\n",
    "        text.set_color('black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_kerasTotal, tpr_kerasTotal,  color='green', label='Tanh/Adadelta = {:.3f})'.format(auc_kerasTotal))\n",
    "plt.scatter(fpr_kerasTotal[ix], tpr_kerasTotal[ix], marker='o', color='black', label='Best')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}