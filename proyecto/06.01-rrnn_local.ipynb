{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.4 64-bit ('base': conda)",
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f958bdd04a238e53230fa8372db10ddee88fbe838d3660515cd74e50e6d77f98"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "tf.compat.v1.set_random_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "           kepid   kepler_name kepoi_name  koi_disposition  light_flux_0001  \\\n0     10797460.0  Kepler-227 b  K00752.01                1         1.727321   \n1     10811496.0           NaN  K00753.01                0         1.044298   \n2     10848459.0           NaN  K00754.01                0        -0.289601   \n3     10854555.0  Kepler-664 b  K00755.01                1        -0.066347   \n4     10872983.0  Kepler-228 d  K00756.01                1         0.910853   \n...          ...           ...        ...              ...              ...   \n6090  10031643.0           NaN  K07984.01                0         1.326015   \n6091  10090151.0           NaN  K07985.01                0        -0.818461   \n6092  10128825.0           NaN  K07986.01                0        -0.202417   \n6093  10147276.0           NaN  K07987.01                0         0.650887   \n6094  10156110.0           NaN  K07989.01                0         0.515398   \n\n      light_flux_0002  light_flux_0003  light_flux_0004  light_flux_0005  \\\n0            0.728728         1.125654         1.229677         1.327881   \n1            0.961948         1.000986         0.983043         0.983156   \n2           -0.370998        -0.441931        -0.410758        -0.379353   \n3           -0.019535         0.481834        -0.052898        -0.000501   \n4            0.953313         1.121489         0.641881         1.222616   \n...               ...              ...              ...              ...   \n6090        -0.237976         1.031217         1.533878         0.628377   \n6091        -0.582961        -0.804967        -0.881438        -0.608308   \n6092        -0.490636         0.925138         0.894101         1.454064   \n6093         0.889116         0.758458         0.425697         0.726841   \n6094         0.319045         0.771879         0.206895         0.714990   \n\n      light_flux_0006  ...  light_flux_0092  light_flux_0093  light_flux_0094  \\\n0            1.390140  ...         1.318587         1.390135         0.968716   \n1            1.037890  ...         1.023945         0.999707         0.986407   \n2           -0.507287  ...        -0.445697        -0.442599        -0.365730   \n3            0.402655  ...        -0.620233        -0.403630        -0.347501   \n4            0.878186  ...         1.040783         0.863073         1.246061   \n...               ...  ...              ...              ...              ...   \n6090         1.317783  ...         0.231072         0.877314         1.741571   \n6091        -0.630170  ...        -0.821112        -0.787683        -0.549940   \n6092        -0.070774  ...         1.194394        -0.265945        -0.643078   \n6093         1.090262  ...         0.987756         0.594261         0.684510   \n6094        -0.292212  ...         1.058577         0.141102        -0.132169   \n\n      light_flux_0095  light_flux_0096  light_flux_0097  light_flux_0098  \\\n0            1.285568         1.216662         0.874477         1.627442   \n1            0.980490         1.018677         0.976698         0.933617   \n2           -0.381951        -0.287742        -0.285504        -0.269432   \n3           -0.388085        -0.302855        -0.130258        -0.042718   \n4            0.969055         1.318099         1.276269         1.092889   \n...               ...              ...              ...              ...   \n6090         1.331278         1.134218         1.485683         0.323981   \n6091        -0.806678        -0.688768        -0.796852        -0.617750   \n6092         0.907540         1.074063         1.982618         0.704504   \n6093         1.125490         0.726558         0.479359        -0.267394   \n6094         0.499010         0.158405         0.809767        -1.000000   \n\n      light_flux_0099  light_flux_0100  light_flux_0101  \n0            0.960296         0.998560         1.489279  \n1            1.067080         1.002989         1.012337  \n2           -0.261419        -0.224786        -0.308863  \n3            0.674248        -0.583962         0.165856  \n4            0.842558         1.081244         0.972349  \n...               ...              ...              ...  \n6090        -0.605954         0.691033         1.012538  \n6091        -0.695399        -0.710079        -0.551582  \n6092         1.937049         0.038070         1.604524  \n6093         0.273248         1.216787         0.561130  \n6094         0.114040         0.090883         0.261374  \n\n[6095 rows x 105 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>kepid</th>\n      <th>kepler_name</th>\n      <th>kepoi_name</th>\n      <th>koi_disposition</th>\n      <th>light_flux_0001</th>\n      <th>light_flux_0002</th>\n      <th>light_flux_0003</th>\n      <th>light_flux_0004</th>\n      <th>light_flux_0005</th>\n      <th>light_flux_0006</th>\n      <th>...</th>\n      <th>light_flux_0092</th>\n      <th>light_flux_0093</th>\n      <th>light_flux_0094</th>\n      <th>light_flux_0095</th>\n      <th>light_flux_0096</th>\n      <th>light_flux_0097</th>\n      <th>light_flux_0098</th>\n      <th>light_flux_0099</th>\n      <th>light_flux_0100</th>\n      <th>light_flux_0101</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>10797460.0</td>\n      <td>Kepler-227 b</td>\n      <td>K00752.01</td>\n      <td>1</td>\n      <td>1.727321</td>\n      <td>0.728728</td>\n      <td>1.125654</td>\n      <td>1.229677</td>\n      <td>1.327881</td>\n      <td>1.390140</td>\n      <td>...</td>\n      <td>1.318587</td>\n      <td>1.390135</td>\n      <td>0.968716</td>\n      <td>1.285568</td>\n      <td>1.216662</td>\n      <td>0.874477</td>\n      <td>1.627442</td>\n      <td>0.960296</td>\n      <td>0.998560</td>\n      <td>1.489279</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>10811496.0</td>\n      <td>NaN</td>\n      <td>K00753.01</td>\n      <td>0</td>\n      <td>1.044298</td>\n      <td>0.961948</td>\n      <td>1.000986</td>\n      <td>0.983043</td>\n      <td>0.983156</td>\n      <td>1.037890</td>\n      <td>...</td>\n      <td>1.023945</td>\n      <td>0.999707</td>\n      <td>0.986407</td>\n      <td>0.980490</td>\n      <td>1.018677</td>\n      <td>0.976698</td>\n      <td>0.933617</td>\n      <td>1.067080</td>\n      <td>1.002989</td>\n      <td>1.012337</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>10848459.0</td>\n      <td>NaN</td>\n      <td>K00754.01</td>\n      <td>0</td>\n      <td>-0.289601</td>\n      <td>-0.370998</td>\n      <td>-0.441931</td>\n      <td>-0.410758</td>\n      <td>-0.379353</td>\n      <td>-0.507287</td>\n      <td>...</td>\n      <td>-0.445697</td>\n      <td>-0.442599</td>\n      <td>-0.365730</td>\n      <td>-0.381951</td>\n      <td>-0.287742</td>\n      <td>-0.285504</td>\n      <td>-0.269432</td>\n      <td>-0.261419</td>\n      <td>-0.224786</td>\n      <td>-0.308863</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>10854555.0</td>\n      <td>Kepler-664 b</td>\n      <td>K00755.01</td>\n      <td>1</td>\n      <td>-0.066347</td>\n      <td>-0.019535</td>\n      <td>0.481834</td>\n      <td>-0.052898</td>\n      <td>-0.000501</td>\n      <td>0.402655</td>\n      <td>...</td>\n      <td>-0.620233</td>\n      <td>-0.403630</td>\n      <td>-0.347501</td>\n      <td>-0.388085</td>\n      <td>-0.302855</td>\n      <td>-0.130258</td>\n      <td>-0.042718</td>\n      <td>0.674248</td>\n      <td>-0.583962</td>\n      <td>0.165856</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>10872983.0</td>\n      <td>Kepler-228 d</td>\n      <td>K00756.01</td>\n      <td>1</td>\n      <td>0.910853</td>\n      <td>0.953313</td>\n      <td>1.121489</td>\n      <td>0.641881</td>\n      <td>1.222616</td>\n      <td>0.878186</td>\n      <td>...</td>\n      <td>1.040783</td>\n      <td>0.863073</td>\n      <td>1.246061</td>\n      <td>0.969055</td>\n      <td>1.318099</td>\n      <td>1.276269</td>\n      <td>1.092889</td>\n      <td>0.842558</td>\n      <td>1.081244</td>\n      <td>0.972349</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>6090</td>\n      <td>10031643.0</td>\n      <td>NaN</td>\n      <td>K07984.01</td>\n      <td>0</td>\n      <td>1.326015</td>\n      <td>-0.237976</td>\n      <td>1.031217</td>\n      <td>1.533878</td>\n      <td>0.628377</td>\n      <td>1.317783</td>\n      <td>...</td>\n      <td>0.231072</td>\n      <td>0.877314</td>\n      <td>1.741571</td>\n      <td>1.331278</td>\n      <td>1.134218</td>\n      <td>1.485683</td>\n      <td>0.323981</td>\n      <td>-0.605954</td>\n      <td>0.691033</td>\n      <td>1.012538</td>\n    </tr>\n    <tr>\n      <td>6091</td>\n      <td>10090151.0</td>\n      <td>NaN</td>\n      <td>K07985.01</td>\n      <td>0</td>\n      <td>-0.818461</td>\n      <td>-0.582961</td>\n      <td>-0.804967</td>\n      <td>-0.881438</td>\n      <td>-0.608308</td>\n      <td>-0.630170</td>\n      <td>...</td>\n      <td>-0.821112</td>\n      <td>-0.787683</td>\n      <td>-0.549940</td>\n      <td>-0.806678</td>\n      <td>-0.688768</td>\n      <td>-0.796852</td>\n      <td>-0.617750</td>\n      <td>-0.695399</td>\n      <td>-0.710079</td>\n      <td>-0.551582</td>\n    </tr>\n    <tr>\n      <td>6092</td>\n      <td>10128825.0</td>\n      <td>NaN</td>\n      <td>K07986.01</td>\n      <td>0</td>\n      <td>-0.202417</td>\n      <td>-0.490636</td>\n      <td>0.925138</td>\n      <td>0.894101</td>\n      <td>1.454064</td>\n      <td>-0.070774</td>\n      <td>...</td>\n      <td>1.194394</td>\n      <td>-0.265945</td>\n      <td>-0.643078</td>\n      <td>0.907540</td>\n      <td>1.074063</td>\n      <td>1.982618</td>\n      <td>0.704504</td>\n      <td>1.937049</td>\n      <td>0.038070</td>\n      <td>1.604524</td>\n    </tr>\n    <tr>\n      <td>6093</td>\n      <td>10147276.0</td>\n      <td>NaN</td>\n      <td>K07987.01</td>\n      <td>0</td>\n      <td>0.650887</td>\n      <td>0.889116</td>\n      <td>0.758458</td>\n      <td>0.425697</td>\n      <td>0.726841</td>\n      <td>1.090262</td>\n      <td>...</td>\n      <td>0.987756</td>\n      <td>0.594261</td>\n      <td>0.684510</td>\n      <td>1.125490</td>\n      <td>0.726558</td>\n      <td>0.479359</td>\n      <td>-0.267394</td>\n      <td>0.273248</td>\n      <td>1.216787</td>\n      <td>0.561130</td>\n    </tr>\n    <tr>\n      <td>6094</td>\n      <td>10156110.0</td>\n      <td>NaN</td>\n      <td>K07989.01</td>\n      <td>0</td>\n      <td>0.515398</td>\n      <td>0.319045</td>\n      <td>0.771879</td>\n      <td>0.206895</td>\n      <td>0.714990</td>\n      <td>-0.292212</td>\n      <td>...</td>\n      <td>1.058577</td>\n      <td>0.141102</td>\n      <td>-0.132169</td>\n      <td>0.499010</td>\n      <td>0.158405</td>\n      <td>0.809767</td>\n      <td>-1.000000</td>\n      <td>0.114040</td>\n      <td>0.090883</td>\n      <td>0.261374</td>\n    </tr>\n  </tbody>\n</table>\n<p>6095 rows × 105 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Cargo los csv\n",
    "df_local = pd.read_csv(\"./unified-lightcurves-local.csv\").iloc[:, 1:]\n",
    "\n",
    "display(df_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fluxes = df_local.iloc[:,4:]\n",
    "local_labels = df_local.iloc[:,3]"
   ]
  },
  {
   "source": [
    "## Particionado de datos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_local_train, x_local_test, y_local_train, y_local_test = train_test_split(\n",
    "    local_fluxes, local_labels, test_size=0.3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4266, 101) (1829, 101) (4266,) (1829,)\n"
     ]
    }
   ],
   "source": [
    "print(x_local_train.shape, x_local_test.shape, y_local_train.shape, y_local_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos las dimensiones\n",
    "n_outputs = 1\n",
    "n_local_timesteps, n_local_features  = x_local_train.shape[0], x_local_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4266 101\n"
     ]
    }
   ],
   "source": [
    "print(n_local_timesteps, n_local_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expandimos las dimensiones de train \n",
    "x_local_extended_train = np.expand_dims(x_local_train,axis=-1) \n",
    "y_local_extended_train = np.array(y_local_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4266, 101) (4266,)\n",
      "(4266, 101, 1) (4266,)\n"
     ]
    }
   ],
   "source": [
    "print(x_local_train.shape, y_local_train.shape)\n",
    "print(x_local_extended_train.shape, y_local_extended_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expandimos las dimensiones de test\n",
    "x_local_extended_test = np.expand_dims(x_local_test,axis=-1)\n",
    "y_local_extended_test = np.array(y_local_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1829, 101) (1829,)\n(1829, 101, 1) (1829,)\n"
     ]
    }
   ],
   "source": [
    "print(x_local_test.shape, y_local_test.shape)\n",
    "print(x_local_extended_test.shape, y_local_extended_test.shape)"
   ]
  },
  {
   "source": [
    "## Construcción Red Neuronal"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Red para vistas locales"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first input model\n",
    "inputLocalView = tf.keras.layers.Input(shape=(n_local_features, 1))\n",
    "inputLocalView.set_shape([n_local_timesteps, n_local_features, 1]) # 4266 x 101\n",
    "\n",
    "CL1 = tf.keras.layers.Conv1D(filters=16, kernel_size=5, activation='relu')(inputLocalView)\n",
    "CL2 = tf.keras.layers.Conv1D(filters=16, kernel_size=5, activation='relu')(CL1)\n",
    "\n",
    "ML1 = tf.keras.layers.MaxPooling1D(pool_size=7, strides=2)(CL2)\n",
    "\n",
    "CL3 = tf.keras.layers.Conv1D(filters=32, kernel_size=5, activation='relu')(ML1)\n",
    "CL4 = tf.keras.layers.Conv1D(filters=32, kernel_size=5, activation='relu')(CL3)\n",
    "\n",
    "ML2 = tf.keras.layers.MaxPooling1D(pool_size=7, strides=2)(CL4)\n",
    "#flat1 = tf.keras.layers.Flatten()(ML2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpretation model\n",
    "hidden1 = tf.keras.layers.Dense(256, activation='relu')(ML2)\n",
    "hidden2 = tf.keras.layers.Dense(256, activation='relu')(hidden1)\n",
    "hidden3 = tf.keras.layers.Dense(256, activation='relu')(hidden2)\n",
    "hidden4 = tf.keras.layers.Dense(256, activation='relu')(hidden3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(4266, 101, 1)]          0         \n_________________________________________________________________\nconv1d (Conv1D)              (4266, 97, 16)            96        \n_________________________________________________________________\nconv1d_1 (Conv1D)            (4266, 93, 16)            1296      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (4266, 44, 16)            0         \n_________________________________________________________________\nconv1d_2 (Conv1D)            (4266, 40, 32)            2592      \n_________________________________________________________________\nconv1d_3 (Conv1D)            (4266, 36, 32)            5152      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (4266, 15, 32)            0         \n_________________________________________________________________\ndense (Dense)                (4266, 15, 256)           8448      \n_________________________________________________________________\ndense_1 (Dense)              (4266, 15, 256)           65792     \n_________________________________________________________________\ndense_2 (Dense)              (4266, 15, 256)           65792     \n_________________________________________________________________\ndense_3 (Dense)              (4266, 15, 256)           65792     \n_________________________________________________________________\ndense_4 (Dense)              (4266, 15, 1)             257       \n=================================================================\nTotal params: 215,217\nTrainable params: 215,217\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "output = tf.keras.layers.Dense(n_outputs, activation='tanh')(hidden4)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputLocalView, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (4266, 101, 1) for input Tensor(\"input_1:0\", shape=(4266, 101, 1), dtype=float32), but it was called on an input with incompatible shape (237, 101, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (4266, 101, 1) for input Tensor(\"input_1:0\", shape=(4266, 101, 1), dtype=float32), but it was called on an input with incompatible shape (237, 101, 1).\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 1.1260 - accuracy: 0.7357\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 2s 84ms/step - loss: 0.5379 - accuracy: 0.7581\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 1s 80ms/step - loss: 0.5171 - accuracy: 0.7567\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 0.5047 - accuracy: 0.7554\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 2s 85ms/step - loss: 0.4921 - accuracy: 0.7550\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.4875 - accuracy: 0.7588\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 2s 85ms/step - loss: 0.4818 - accuracy: 0.7678\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 1s 79ms/step - loss: 0.4698 - accuracy: 0.7755\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.4688 - accuracy: 0.7815\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 2s 96ms/step - loss: 0.4700 - accuracy: 0.7791\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 2s 85ms/step - loss: 0.4599 - accuracy: 0.7849\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 1s 80ms/step - loss: 0.4559 - accuracy: 0.7897\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 2s 84ms/step - loss: 0.4478 - accuracy: 0.7940\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 2s 87ms/step - loss: 0.4437 - accuracy: 0.7955\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 1s 81ms/step - loss: 0.4603 - accuracy: 0.7914\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 1s 83ms/step - loss: 0.4502 - accuracy: 0.7928\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 2s 87ms/step - loss: 0.4432 - accuracy: 0.7965\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 2s 83ms/step - loss: 0.4396 - accuracy: 0.7992\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 1s 79ms/step - loss: 0.4397 - accuracy: 0.7966\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 1s 78ms/step - loss: 0.4302 - accuracy: 0.8030\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 1s 77ms/step - loss: 0.4272 - accuracy: 0.8066\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 1s 80ms/step - loss: 0.4415 - accuracy: 0.8006\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 2s 87ms/step - loss: 0.4368 - accuracy: 0.8063\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.4283 - accuracy: 0.8048\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 0.4220 - accuracy: 0.8096\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 2s 86ms/step - loss: 0.4192 - accuracy: 0.8125\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 1s 83ms/step - loss: 0.4176 - accuracy: 0.8096\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 1s 82ms/step - loss: 0.4167 - accuracy: 0.8121\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 1s 83ms/step - loss: 0.4160 - accuracy: 0.8130\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 2s 84ms/step - loss: 0.4196 - accuracy: 0.8098\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 0.4122 - accuracy: 0.8142\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 2s 86ms/step - loss: 0.4076 - accuracy: 0.8169\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 0.4181 - accuracy: 0.8105\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.4101 - accuracy: 0.8129\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 2s 92ms/step - loss: 0.4009 - accuracy: 0.8200\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.4006 - accuracy: 0.8203\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.4046 - accuracy: 0.8182\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 2s 85ms/step - loss: 0.3983 - accuracy: 0.8206\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 2s 83ms/step - loss: 0.4023 - accuracy: 0.8189\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 1s 83ms/step - loss: 0.3993 - accuracy: 0.8227\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 0.3907 - accuracy: 0.8254\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 2s 84ms/step - loss: 0.4049 - accuracy: 0.8155\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 2s 91ms/step - loss: 0.3900 - accuracy: 0.8256\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 0.3925 - accuracy: 0.8252\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 0.3835 - accuracy: 0.8290\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 2s 95ms/step - loss: 0.3915 - accuracy: 0.8267\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 2s 94ms/step - loss: 0.3899 - accuracy: 0.8254\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 2s 93ms/step - loss: 0.3895 - accuracy: 0.8247\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 2s 100ms/step - loss: 0.3775 - accuracy: 0.8314\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 2s 97ms/step - loss: 0.3791 - accuracy: 0.8315\n"
     ]
    }
   ],
   "source": [
    "# divisores 4266: 1, 2, 3, 6, 9, 18, 27, 54, 79, 158, 237, 474, 711, 1422, 2133, 4266\n",
    "bs = 237\n",
    "Ajuste = model.fit(x_local_extended_train, y_local_extended_train, epochs=50, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras = model.predict(x_local_extended_test).ravel() # Return a contiguous flattened array\n",
    "display(y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino las métricas\n",
    "# false positive rates / true positive rates / Decreasing thresholds on the decision function\n",
    "fpr_keras, tpr_keras, thresholds_keras = sklearn.metrics.roc_curve(y_local_extended_test, y_pred_keras)\n",
    "auc_keras = sklearn.metrics.auc(fpr_keras, tpr_keras) # Area Under the Curve\n",
    "gmeans = np.sqrt(tpr_keras * (1-fpr_keras))\n",
    "\n",
    "# localiza el índice del mayor g-mean\n",
    "ix = np.argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds_keras[ix], gmeans[ix]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umbral estándar\n",
    "labels_Standart = (y_pred_keras >= 0.5).astype(np.int)\n",
    "PhiM_Standart = sklearn.metrics.matthews_corrcoef(y_local_extended_test, labels_Standart)\n",
    "Matrix_Standart = sklearn.metrics.confusion_matrix(y_local_extended_test, labels_Standart)\n",
    "\n",
    "#Imprimo por pantalla las métricas\n",
    "auc_keras, PhiM_Standart, print(Matrix_Standart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umbral OPT\n",
    "labels_OPT =(y_pred_keras >= thresholds_keras[ix]).astype(np.int)\n",
    "PhiCoeff_OPT = sklearn.metrics.matthews_corrcoef(y_local_extended_test, labels_OPT)\n",
    "Matrix_OPT = sklearn.metrics.confusion_matrix(y_local_extended_test, labels_OPT)\n",
    "F_Measure_OPT = sklearn.metrics.f1_score(y_local_extended_test, labels_OPT, average='binary')\n",
    "Accuracy_OPT= sklearn.metrics.accuracy_score(y_local_extended_test, labels_OPT, normalize=True)\n",
    "Recall_OPT= sklearn.metrics.recall_score(y_local_extended_test, labels_OPT, average=None)\n",
    "Average_precision_OPT= sklearn.metrics.average_precision_score(y_local_extended_test, labels_OPT)\n",
    "\n",
    "\n",
    "#Imprimo por pantalla las métricas\n",
    "print(\"AUC:\", auc_keras)\n",
    "print(\"F_Measure:\", F_Measure_OPT)\n",
    "print(\"PhiCoeff:\", PhiCoeff_OPT)\n",
    "print(\"Average_precision:\", Average_precision_OPT)\n",
    "print(\"Accuracy:\", Accuracy_OPT)\n",
    "print(\"Recall:\", Recall_OPT)\n",
    "print(\"Matriz de confusión:\")\n",
    "print( Matrix_OPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploteo la matrix de confusión\n",
    "import seaborn as sn\n",
    "df_cm = pd.DataFrame(Matrix_OPT, index = [i for i in \"01\"],\n",
    "                  columns = [i for i in \"01\"])\n",
    "\n",
    "plt.figure(0.5)\n",
    "heat_map = sn.heatmap(df_cm, xticklabels=True, yticklabels=True, annot=True, annot_kws = {\"ha\": 'center',\"va\": 'bottom'},cbar=False)\n",
    "#heat_map.set_yticklabels(heat_map.get_yticklabels(), rotation=0)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "for text in heat_map.texts:\n",
    "    text.set_size(14)\n",
    "    text.set_weight('bold')\n",
    "    if text.get_text() == '5':\n",
    "        text.set_color('black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='CNN (area = {:.3f})'.format(auc_keras))\n",
    "plt.scatter(fpr_keras[ix], tpr_keras[ix], marker='o', color='black', label='Best')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}